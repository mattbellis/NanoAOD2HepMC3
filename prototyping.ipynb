{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0a33f1-93be-47bd-8299-a2b172e6c29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "\n",
    "import pyhepmc as hp\n",
    "from particle import Particle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc64ef62-c24b-4bd7-8b7f-615e305bbd98",
   "metadata": {},
   "source": [
    "# Download files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d277ab96-9de0-4f7f-975f-f348eab38dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!xrdcp root://eospublic.cern.ch//eos/opendata/cms/mc/RunIISummer20UL16NanoAODv9/TTZToLLNuNu_M-10_TuneCP5CR1_13TeV-amcatnlo-pythia8/NANOAODSIM/106X_mcRun2_asymptotic_v17-v2/2520000/FD6F2D88-5C5C-B844-BA34-B1D2411B0427.root ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c3d021-dbbb-41e1-9718-b9c2d2896e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# Helpers\n",
    "# ------------------------\n",
    "# Is 1e6 the right way to go?\n",
    "############ PRODUCES 0 for the energy of the beam\n",
    "############ SHOULD WE GET THIS FROM LHE?\n",
    "def four_vector_from_pt_eta_phi_m(pt, eta, phi, mass, eta_max=10):\n",
    "    \"\"\"\n",
    "    Build (px, py, pz, E) from (pt, eta, phi, mass).\n",
    "    To avoid overflow in sinh/cosh for crazy |eta|, we clip |eta| to eta_max.\n",
    "    \"\"\"\n",
    "    # NumPy handles both scalars and arrays here\n",
    "    eta_clipped = np.clip(eta, -eta_max, eta_max)\n",
    "\n",
    "    px = pt * np.cos(phi)\n",
    "    py = pt * np.sin(phi)\n",
    "    pz = pt * np.sinh(eta_clipped)\n",
    "\n",
    "    # E^2 = p^2 + m^2, with pT * cosh(eta)\n",
    "    e2 = (pt * np.cosh(eta_clipped)) ** 2 + mass ** 2\n",
    "\n",
    "    if np.isscalar(e2):\n",
    "        if e2 < 0:\n",
    "            e2 = 0.0\n",
    "        e = math.sqrt(e2)\n",
    "    else:\n",
    "        e2 = np.where(e2 < 0, 0.0, e2)\n",
    "        e = np.sqrt(e2)\n",
    "\n",
    "    return px, py, pz, e\n",
    "\n",
    "\n",
    "def infer_mass(pdg_id, stored_mass):\n",
    "    \"\"\"\n",
    "    Use stored mass when > 0, otherwise fall back to PDG mass (via particle package).\n",
    "    You can skip this and just return stored_mass if you prefer the NanoAOD value.\n",
    "    \"\"\"\n",
    "    if stored_mass > 0:\n",
    "        return stored_mass\n",
    "    try:\n",
    "        p = Particle.from_pdgid(int(pdg_id))\n",
    "        if p.mass is None:\n",
    "            return 0.0\n",
    "        # particle gives mass in MeV\n",
    "        return p.mass / 1000.0\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# Converter class\n",
    "# ------------------------\n",
    "\n",
    "class NanoAODToHepMCConverter:\n",
    "    \"\"\"\n",
    "    Minimal CMS NanoAOD → HepMC3 converter focused on generator-level info.\n",
    "\n",
    "    Typical notebook usage:\n",
    "        conv = NanoAODToHepMCConverter(\"file.root\")\n",
    "        conv.convert_file(\"out.hepmc\", max_events=100)\n",
    "\n",
    "    For prototyping individual events:\n",
    "        arrays = uproot.open(\"file.root:Events\").arrays(conv.required_branches(), library=\"ak\")\n",
    "        evt0 = conv.build_hepmc_event(arrays, 0)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        nanoaod_file: str,\n",
    "        tree_name: str = \"Events\",\n",
    "        use_pdg_masses: bool = True,\n",
    "    ):\n",
    "        self.filename = nanoaod_file\n",
    "        self.tree_name = tree_name\n",
    "        self.use_pdg_masses = use_pdg_masses\n",
    "\n",
    "        # Branches we’ll read\n",
    "        self.genpart_branches = [\n",
    "            \"nGenPart\",\n",
    "            \"GenPart_pt\",\n",
    "            \"GenPart_eta\",\n",
    "            \"GenPart_phi\",\n",
    "            \"GenPart_mass\",\n",
    "            \"GenPart_pdgId\",\n",
    "            \"GenPart_status\",\n",
    "            \"GenPart_genPartIdxMother\",\n",
    "        ]\n",
    "\n",
    "        self.event_branches = [\n",
    "            \"genWeight\",\n",
    "            \"Generator_id1\",\n",
    "            \"Generator_id2\",\n",
    "            \"Generator_scalePDF\",\n",
    "            \"Generator_x1\",\n",
    "            \"Generator_x2\",\n",
    "            \"Generator_xpdf1\",\n",
    "            \"Generator_xpdf2\",\n",
    "        ]\n",
    "\n",
    "        # New: one shared GenRunInfo for all events\n",
    "        self.run_info = hp.GenRunInfo()\n",
    "        self.run_info.weight_names = [\"genWeight\"]\n",
    "    \n",
    "    # ------------ public helpers for notebook use ------------\n",
    "\n",
    "    def required_branches(self):\n",
    "        \"\"\"All branch names needed to build a HepMC event.\"\"\"\n",
    "        return list(set(self.genpart_branches + self.event_branches))\n",
    "\n",
    "    def convert_file(\n",
    "        self,\n",
    "        output_hepmc_file: str,\n",
    "        max_events: int | None = None,\n",
    "        step_size: str | int = \"100 MB\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Convert all (or first max_events) events from the NanoAOD file to HepMC3.\n",
    "\n",
    "        Writes an ASCII HepMC3 file using pyhepmc.\n",
    "        \"\"\"\n",
    "        with hp.open(output_hepmc_file, \"w\") as hepmc_out:\n",
    "            events_processed = 0\n",
    "\n",
    "            for arrays in uproot.iterate(\n",
    "                f\"{self.filename}:{self.tree_name}\",\n",
    "                filter_name=self.required_branches(),\n",
    "                step_size=step_size,\n",
    "                library=\"ak\",\n",
    "            ):\n",
    "                n_events_chunk = len(arrays[\"nGenPart\"])\n",
    "\n",
    "                for i_evt in range(n_events_chunk):\n",
    "                    if max_events is not None and events_processed >= max_events:\n",
    "                        return\n",
    "\n",
    "                    event = self.build_hepmc_event(arrays, i_evt)\n",
    "                    hepmc_out.write(event)\n",
    "                    events_processed += 1\n",
    "\n",
    "    def build_hepmc_events_from_arrays(self, arrays):\n",
    "        \"\"\"\n",
    "        Convenience: build a list of HepMC events from an awkward record of NanoAOD arrays.\n",
    "        This is useful if you already have arrays in memory in your notebook.\n",
    "        \"\"\"\n",
    "        n_events = len(arrays[\"nGenPart\"])\n",
    "        return [self.build_hepmc_event(arrays, i_evt) for i_evt in range(n_events)]\n",
    "\n",
    "    # ------------ core event builder ------------\n",
    "\n",
    "    def build_hepmc_event(self, arrays, i_evt: int):\n",
    "        \"\"\"\n",
    "        Build a single HepMC3 GenEvent from an event in the nanoAOD awkward arrays.\n",
    "        `arrays` is typically one chunk from uproot.iterate or the result of .arrays().\n",
    "        \"\"\"\n",
    "        # Create event (default units: GeV & mm)\n",
    "        event = hp.GenEvent(\n",
    "            hp.Units.MomentumUnit.GEV,\n",
    "            hp.Units.LengthUnit.MM,\n",
    "        )\n",
    "\n",
    "        # Attach shared run_info (so writer sees same object each time)\n",
    "        event.run_info = self.run_info\n",
    "\n",
    "        \n",
    "        # === Event weight ===\n",
    "        if \"genWeight\" in arrays.fields:\n",
    "            w = float(arrays[\"genWeight\"][i_evt])\n",
    "            event.weights = [w]\n",
    "\n",
    "            # Give the weight a name via run_info\n",
    "            if event.run_info is None:\n",
    "                event.run_info = hp.GenRunInfo()\n",
    "            event.run_info.weight_names = [\"genWeight\"]\n",
    "\n",
    "        # === PDF info (if present) ===\n",
    "        pdf_fields = self.event_branches[1:]  # skip genWeight\n",
    "        if all(b in arrays.fields for b in pdf_fields):\n",
    "            pdfinfo = hp.GenPdfInfo()\n",
    "            pdfinfo.parton_id1 = int(arrays[\"Generator_id1\"][i_evt])\n",
    "            pdfinfo.parton_id2 = int(arrays[\"Generator_id2\"][i_evt])\n",
    "            pdfinfo.scale = float(arrays[\"Generator_scalePDF\"][i_evt])\n",
    "            pdfinfo.x1 = float(arrays[\"Generator_x1\"][i_evt])\n",
    "            pdfinfo.x2 = float(arrays[\"Generator_x2\"][i_evt])\n",
    "            pdfinfo.xf1 = float(arrays[\"Generator_xpdf1\"][i_evt])\n",
    "            pdfinfo.xf2 = float(arrays[\"Generator_xpdf2\"][i_evt])\n",
    "            event.attributes[\"GenPdfInfo\"] = pdfinfo\n",
    "\n",
    "        # === GenParticles ===\n",
    "        pt        = arrays[\"GenPart_pt\"][i_evt]\n",
    "        eta       = arrays[\"GenPart_eta\"][i_evt]\n",
    "        phi       = arrays[\"GenPart_phi\"][i_evt]\n",
    "        mass_arr  = arrays[\"GenPart_mass\"][i_evt]\n",
    "        pdgId     = arrays[\"GenPart_pdgId\"][i_evt]\n",
    "        status    = arrays[\"GenPart_status\"][i_evt]\n",
    "        mother_idx = arrays[\"GenPart_genPartIdxMother\"][i_evt]\n",
    "\n",
    "        n_genpart = len(pt)\n",
    "        hepmc_particles = []\n",
    "\n",
    "        for i in range(n_genpart):\n",
    "            raw_mass = float(mass_arr[i])\n",
    "            m_val = (\n",
    "                infer_mass(int(pdgId[i]), raw_mass)\n",
    "                if self.use_pdg_masses\n",
    "                else raw_mass\n",
    "            )\n",
    "\n",
    "            px, py, pz, e = four_vector_from_pt_eta_phi_m(\n",
    "                float(pt[i]),\n",
    "                float(eta[i]),\n",
    "                float(phi[i]),\n",
    "                m_val,\n",
    "            )\n",
    "\n",
    "            fv = hp.FourVector(px, py, pz, e)\n",
    "            p = hp.GenParticle(fv, int(pdgId[i]), int(status[i]))\n",
    "            event.add_particle(p)\n",
    "            hepmc_particles.append(p)\n",
    "\n",
    "        # === Vertices from mother indices ===\n",
    "        # Map: mother index -> GenVertex\n",
    "        decay_vertices: dict[int, hp.GenVertex] = {}\n",
    "\n",
    "        for i in range(n_genpart):\n",
    "            m = int(mother_idx[i])\n",
    "            if m < 0 or m >= n_genpart:\n",
    "                continue  # no valid mother → primordial for now\n",
    "\n",
    "            if m not in decay_vertices:\n",
    "                # Place all vertices at origin for now (can use GenVtx later)\n",
    "                vtx = hp.GenVertex(hp.FourVector(0.0, 0.0, 0.0, 0.0))\n",
    "                event.add_vertex(vtx)\n",
    "                # incoming = mother\n",
    "                vtx.add_particle_in(hepmc_particles[m])\n",
    "                decay_vertices[m] = vtx\n",
    "            else:\n",
    "                vtx = decay_vertices[m]\n",
    "\n",
    "            # outgoing = this particle\n",
    "            vtx.add_particle_out(hepmc_particles[i])\n",
    "\n",
    "        return event\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518435a8-3a9c-4da4-b2cf-d3c95d360e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "infilename = 'FD6F2D88-5C5C-B844-BA34-B1D2411B0427.root'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf26830-e9b0-46be-8706-b227ff320b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = NanoAODToHepMCConverter(infilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae7f5d1-e502-4438-a7f5-01e1ac96eb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert first 100 events (or drop max_events to do all)\n",
    "conv.convert_file(\"test_output.hepmc3\", max_events=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ebcdd4-b686-48b2-811c-c3efb377e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull a small batch of events into memory\n",
    "events_tree = uproot.open(f\"{infilename}:Events\")\n",
    "arrays_small = events_tree.arrays(conv.required_branches(), entry_stop=10, library=\"ak\")\n",
    "\n",
    "# Build HepMC events in memory\n",
    "hepmc_events = conv.build_hepmc_events_from_arrays(arrays_small)\n",
    "\n",
    "len(hepmc_events), type(hepmc_events[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609731c1-b166-409d-a211-4b9db78ecb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hepmc_events[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579a8c21-54ca-469d-b56b-036f16ebd04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hp.listing(hepmc_events[0], precision=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62309593-b21f-4033-957d-0ed785787f87",
   "metadata": {},
   "source": [
    "# NanoAOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1c0b24-ccea-4d3e-ac89-02a7a9e65509",
   "metadata": {},
   "outputs": [],
   "source": [
    "gentree_pt = events_tree['GenPart_pt']\n",
    "gentree_eta = events_tree['GenPart_eta']\n",
    "gentree_e = events_tree['GenPart_mass']\n",
    "\n",
    "gentree_status = events_tree['GenPart_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd647073-3f5f-4d06-825b-fcfd3c5c8c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "\n",
    "print(gentree_pt.array()[0][n])\n",
    "print(gentree_status.array()[0][n])\n",
    "print(gentree_eta.array()[0][n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afdaec0-8308-49c7-b10a-ec6f7425e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(gentree_eta.array()[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d772207-2f97-4008-ac03-41940b4668c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 2.4e4\n",
    "#eta = 100\n",
    "\n",
    "eta_max = 2.5e4\n",
    "eta_clipped = np.clip(eta, -eta_max, eta_max)\n",
    "\n",
    "print(eta_clipped)\n",
    "\n",
    "np.sinh(eta_clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fbe5b0-1f8b-4308-90c7-c29235ebc444",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_tree['GenPart_pdgId'].array()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3748586-72f8-44c0-8150-a17d8506ee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_tree['GenPart_mass'].array()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6c0b5b-a611-41ec-ac94-f22bc5a47513",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_tree['LHEPart_incomingpz'].array()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa905eb-dc65-4471-8016-aed9e47ea0fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
